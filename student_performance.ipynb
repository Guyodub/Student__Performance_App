{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"student/student-mat.csv\", sep=';', encoding='utf8')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 33 columns):\n",
      "school        395 non-null object\n",
      "sex           395 non-null object\n",
      "age           395 non-null int64\n",
      "address       395 non-null object\n",
      "famsize       395 non-null object\n",
      "Pstatus       395 non-null object\n",
      "Medu          395 non-null int64\n",
      "Fedu          395 non-null int64\n",
      "Mjob          395 non-null object\n",
      "Fjob          395 non-null object\n",
      "reason        395 non-null object\n",
      "guardian      395 non-null object\n",
      "traveltime    395 non-null int64\n",
      "studytime     395 non-null int64\n",
      "failures      395 non-null int64\n",
      "schoolsup     395 non-null object\n",
      "famsup        395 non-null object\n",
      "paid          395 non-null object\n",
      "activities    395 non-null object\n",
      "nursery       395 non-null object\n",
      "higher        395 non-null object\n",
      "internet      395 non-null object\n",
      "romantic      395 non-null object\n",
      "famrel        395 non-null int64\n",
      "freetime      395 non-null int64\n",
      "goout         395 non-null int64\n",
      "Dalc          395 non-null int64\n",
      "Walc          395 non-null int64\n",
      "health        395 non-null int64\n",
      "absences      395 non-null int64\n",
      "G1            395 non-null int64\n",
      "G2            395 non-null int64\n",
      "G3            395 non-null int64\n",
      "dtypes: int64(16), object(17)\n",
      "memory usage: 101.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.696203</td>\n",
       "      <td>2.749367</td>\n",
       "      <td>2.521519</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.944304</td>\n",
       "      <td>3.235443</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>1.481013</td>\n",
       "      <td>2.291139</td>\n",
       "      <td>3.554430</td>\n",
       "      <td>5.708861</td>\n",
       "      <td>10.908861</td>\n",
       "      <td>10.713924</td>\n",
       "      <td>10.415190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>1.088201</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.890741</td>\n",
       "      <td>1.287897</td>\n",
       "      <td>1.390303</td>\n",
       "      <td>8.003096</td>\n",
       "      <td>3.319195</td>\n",
       "      <td>3.761505</td>\n",
       "      <td>4.581443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean    16.696203    2.749367    2.521519    1.448101    2.035443    0.334177   \n",
       "std      1.276043    1.094735    1.088201    0.697505    0.839240    0.743651   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    3.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     3.944304    3.235443    3.108861    1.481013    2.291139    3.554430   \n",
       "std      0.896659    0.998862    1.113278    0.890741    1.287897    1.390303   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    3.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences          G1          G2          G3  \n",
       "count  395.000000  395.000000  395.000000  395.000000  \n",
       "mean     5.708861   10.908861   10.713924   10.415190  \n",
       "std      8.003096    3.319195    3.761505    4.581443  \n",
       "min      0.000000    3.000000    0.000000    0.000000  \n",
       "25%      0.000000    8.000000    9.000000    8.000000  \n",
       "50%      4.000000   11.000000   11.000000   11.000000  \n",
       "75%      8.000000   13.000000   13.000000   14.000000  \n",
       "max     75.000000   19.000000   19.000000   20.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school        0\n",
       "sex           0\n",
       "age           0\n",
       "address       0\n",
       "famsize       0\n",
       "Pstatus       0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "Mjob          0\n",
       "Fjob          0\n",
       "reason        0\n",
       "guardian      0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "schoolsup     0\n",
       "famsup        0\n",
       "paid          0\n",
       "activities    0\n",
       "nursery       0\n",
       "higher        0\n",
       "internet      0\n",
       "romantic      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "Dalc          0\n",
       "Walc          0\n",
       "health        0\n",
       "absences      0\n",
       "G1            0\n",
       "G2            0\n",
       "G3            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school',\n",
       " 'sex',\n",
       " 'address',\n",
       " 'famsize',\n",
       " 'Pstatus',\n",
       " 'Mjob',\n",
       " 'Fjob',\n",
       " 'reason',\n",
       " 'guardian',\n",
       " 'schoolsup',\n",
       " 'famsup',\n",
       " 'paid',\n",
       " 'activities',\n",
       " 'nursery',\n",
       " 'higher',\n",
       " 'internet',\n",
       " 'romantic']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#categrorical columns\n",
    "cat_features=[i for i in dataset.columns if dataset.dtypes[i]=='object']\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'Dalc',\n",
       " 'Walc',\n",
       " 'health',\n",
       " 'absences',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'G3']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numeric features\n",
    "num_features = [i for  i in dataset.columns if dataset.dtypes[i]=='int64']\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>activities_no</th>\n",
       "      <th>activities_yes</th>\n",
       "      <th>nursery_no</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_no</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_no</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_no</th>\n",
       "      <th>romantic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     4     4           2          2         0       4         3      4   \n",
       "\n",
       "   Dalc      ...       activities_no  activities_yes  nursery_no  nursery_yes  \\\n",
       "0     1      ...                   1               0           0            1   \n",
       "\n",
       "   higher_no  higher_yes  internet_no  internet_yes  romantic_no  romantic_yes  \n",
       "0          0           1            1             0            1             0  \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode the covariate 'school'\n",
    "one_hot_school = pd.get_dummies(dataset['school'], prefix='school')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_school], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['school'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'sex'\n",
    "one_hot_sex = pd.get_dummies(dataset['sex'], prefix='sex')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_sex], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['sex'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'address'\n",
    "one_hot_address = pd.get_dummies(dataset['address'], prefix='address')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_address], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['address'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# one hot encode the covariate 'famsize'\n",
    "one_hot_famsize = pd.get_dummies(dataset['famsize'], prefix='famsize')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_famsize], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['famsize'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'Pstatus'\n",
    "one_hot_Pstatus = pd.get_dummies(dataset['Pstatus'], prefix='Pstatus')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_Pstatus], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['Pstatus'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'Mjob'\n",
    "one_hot_Mjob = pd.get_dummies(dataset['Mjob'], prefix='Mjob')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_Mjob], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['Mjob'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'Fjob'\n",
    "one_hot_Fjob = pd.get_dummies(dataset['Fjob'], prefix='Fjob')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_Fjob], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['Fjob'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'reason'\n",
    "one_hot_reason = pd.get_dummies(dataset['reason'], prefix='reason')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_reason], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['reason'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'guardian'\n",
    "one_hot_guardian = pd.get_dummies(dataset['guardian'], prefix='guardian')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_guardian], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['guardian'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'schoolsup'\n",
    "one_hot_schoolsup = pd.get_dummies(dataset['schoolsup'], prefix='schoolsup')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_schoolsup], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['schoolsup'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'famsup'\n",
    "one_hot_famsup = pd.get_dummies(dataset['famsup'], prefix='famsup')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_famsup], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['famsup'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'paid'\n",
    "one_hot_paid = pd.get_dummies(dataset['paid'], prefix='paid')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_paid], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['paid'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'activities'\n",
    "one_hot_activities = pd.get_dummies(dataset['activities'], prefix='activities')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_activities], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['activities'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'nursery'\n",
    "one_hot_nursery = pd.get_dummies(dataset['nursery'], prefix='nursery')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_nursery], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['nursery'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'higher'\n",
    "one_hot_higher = pd.get_dummies(dataset['higher'], prefix='higher')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_higher], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['higher'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'internet'\n",
    "one_hot_internet = pd.get_dummies(dataset['internet'], prefix='internet')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_internet], axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "dataset.drop(['internet'], axis=1, inplace=True)\n",
    "\n",
    "# one hot encode the covariate 'romantic'\n",
    "one_hot_romantic = pd.get_dummies(dataset['romantic'], prefix='romantic')\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "dataset = pd.concat([dataset, one_hot_romantic], axis=1)\n",
    "\n",
    "# now drop the original 'romantic' column (you don't need it anymore)\n",
    "dataset.drop(['romantic'], axis=1, inplace=True)\n",
    "\n",
    "# print the resultant dataframe\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'school','sex','address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup',\n",
    " #'paid','activities','nurhigher','internet','romantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2',\n",
       "       'G3', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R',\n",
       "       'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T',\n",
       "       'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services',\n",
       "       'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other',\n",
       "       'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home',\n",
       "       'reason_other', 'reason_reputation', 'guardian_father',\n",
       "       'guardian_mother', 'guardian_other', 'schoolsup_no', 'schoolsup_yes',\n",
       "       'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes', 'activities_no',\n",
       "       'activities_yes', 'nursery_no', 'nursery_yes', 'higher_no',\n",
       "       'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',\n",
       "       'romantic_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_no</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_no</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_no</th>\n",
       "      <th>romantic_yes</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     4     4           2          2         0       4         3      4   \n",
       "\n",
       "   Dalc ...  nursery_yes  higher_no  higher_yes  internet_no  internet_yes  \\\n",
       "0     1 ...            1          0           1            1             0   \n",
       "\n",
       "   romantic_no  romantic_yes  G1  G2  G3  \n",
       "0            1             0   5   6   6  \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
    " 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'school_GP', \n",
    " 'school_MS', 'sex_F', 'sex_M', 'address_R','address_U', 'famsize_GT3', \n",
    " 'famsize_LE3', 'Pstatus_A', 'Pstatus_T','Mjob_at_home', 'Mjob_health', \n",
    " 'Mjob_other', 'Mjob_services','Mjob_teacher', 'Fjob_at_home', 'Fjob_health', \n",
    " 'Fjob_other','Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home',\n",
    " 'reason_other', 'reason_reputation', 'guardian_father','guardian_mother', \n",
    " 'guardian_other', 'schoolsup_no', 'schoolsup_yes','famsup_no', 'famsup_yes', \n",
    " 'paid_no', 'paid_yes', 'activities_no','activities_yes', 'nursery_no', 'nursery_yes', \n",
    " 'higher_no','higher_yes', 'internet_no', 'internet_yes', 'romantic_no','romantic_yes',\n",
    " 'G1', 'G2','G3']]\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>nursery_no</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_no</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_no</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_no</th>\n",
       "      <th>romantic_yes</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     4     4           2          2         0       4         3      4   \n",
       "1   17     1     1           1          2         0       5         3      3   \n",
       "2   15     1     1           1          2         3       4         3      2   \n",
       "\n",
       "   Dalc ...  nursery_no  nursery_yes  higher_no  higher_yes  internet_no  \\\n",
       "0     1 ...           0            1          0           1            1   \n",
       "1     1 ...           1            0          0           1            0   \n",
       "2     2 ...           0            1          0           1            0   \n",
       "\n",
       "   internet_yes  romantic_no  romantic_yes  G1  G2  \n",
       "0             0            1             0   5   6  \n",
       "1             1            1             0   5   5  \n",
       "2             1            1             0   7   8  \n",
       "\n",
       "[3 rows x 58 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=dataset.iloc[:,:-1]\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6\n",
       "1     6\n",
       "2    10\n",
       "Name: G3, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,-1]\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop G1 and G2 colum\n",
    "# X.drop([\"G1\", \"G2\"], axis = 1, inplace = True)\n",
    "# X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'school_GP',\n",
       "       'school_MS', 'sex_F', 'sex_M', 'address_R', 'address_U', 'famsize_GT3',\n",
       "       'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Mjob_at_home', 'Mjob_health',\n",
       "       'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home',\n",
       "       'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher',\n",
       "       'reason_course', 'reason_home', 'reason_other', 'reason_reputation',\n",
       "       'guardian_father', 'guardian_mother', 'guardian_other', 'schoolsup_no',\n",
       "       'schoolsup_yes', 'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes',\n",
       "       'activities_no', 'activities_yes', 'nursery_no', 'nursery_yes',\n",
       "       'higher_no', 'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',\n",
       "       'romantic_yes', 'G1', 'G2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "          oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Feature Importance\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.55067923e-03 2.48995726e-03 2.07018868e-03 8.04897183e-03\n",
      " 8.61364939e-03 1.84785689e-02 8.59763559e-03 2.52876074e-03\n",
      " 6.58533630e-03 2.64855685e-03 2.99132301e-03 7.68755141e-03\n",
      " 3.42952640e-02 2.06658580e-04 2.41125011e-03 1.77850928e-03\n",
      " 1.58098329e-03 4.56703689e-04 2.25940924e-03 1.47630047e-03\n",
      " 4.72489039e-04 9.65819623e-04 4.99755892e-04 4.10585204e-03\n",
      " 1.58832603e-03 3.05121182e-03 5.52085820e-03 3.11965522e-04\n",
      " 1.41279951e-03 7.19973177e-05 4.56751280e-03 6.66938972e-03\n",
      " 1.50273641e-03 2.52697932e-03 5.79397612e-03 5.89083108e-04\n",
      " 2.32234335e-03 1.16894176e-03 4.59597041e-03 3.27863712e-03\n",
      " 3.12188233e-04 7.62429868e-04 5.15926599e-04 1.41671403e-03\n",
      " 1.10672019e-03 1.15097297e-03 2.94642174e-03 1.00122502e-03\n",
      " 1.50205222e-03 1.86057497e-03 1.55290292e-03 1.63913008e-03\n",
      " 1.18063235e-03 4.98902309e-04 3.26787897e-03 2.40219941e-03\n",
      " 2.45091314e-01 5.59018911e-01]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'school_GP',\n",
       "       'school_MS', 'sex_F', 'sex_M', 'address_R', 'address_U', 'famsize_GT3',\n",
       "       'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Mjob_at_home', 'Mjob_health',\n",
       "       'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home',\n",
       "       'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher',\n",
       "       'reason_course', 'reason_home', 'reason_other', 'reason_reputation',\n",
       "       'guardian_father', 'guardian_mother', 'guardian_other', 'schoolsup_no',\n",
       "       'schoolsup_yes', 'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes',\n",
       "       'activities_no', 'activities_yes', 'nursery_no', 'nursery_yes',\n",
       "       'higher_no', 'higher_yes', 'internet_no', 'internet_yes', 'romantic_no',\n",
       "       'romantic_yes', 'G1', 'G2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['G2', 'G1','age', 'Medu', 'Fedu', 'traveltime', 'studytime',\n",
    "       'failures','freetime', 'goout','Walc', 'absences']\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G2</th>\n",
       "      <th>G1</th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Walc</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   G2  G1  age  Medu  Fedu  traveltime  studytime  failures  freetime  goout  \\\n",
       "0   6   5   18     4     4           2          2         0         3      4   \n",
       "1   5   5   17     1     1           1          2         0         3      3   \n",
       "\n",
       "   Walc  absences  \n",
       "0     1         6  \n",
       "1     1         4  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[[ 'G2', 'G1','age', 'Medu', 'Fedu', 'traveltime', 'studytime',\n",
    "       'failures','freetime', 'goout','Walc', 'absences']]\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G2', 'G1', 'age', 'Medu', 'Fedu', 'traveltime', 'studytime',\n",
       "       'failures', 'freetime', 'goout', 'Walc', 'absences'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    131\n",
       "2    103\n",
       "3     99\n",
       "1     59\n",
       "0      3\n",
       "Name: Medu, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Medu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_rf = RandomForestRegressor()\n",
    "reg_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9767229085922895"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526636295439629"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.0924050632911393\n",
      "MSE: 3.021139240506329\n",
      "RMSE: 1.7381424684145799\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526636295439628"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G2', 'G1', 'age', 'Medu', 'Fedu', 'traveltime', 'studytime',\n",
       "       'failures', 'freetime', 'goout', 'Walc', 'absences'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10, total=   4.6s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10, total=   4.8s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10, total=   5.9s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10, total=   6.3s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=sqrt, max_depth=10, total=   5.9s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15, total=   6.6s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15, total=   7.2s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15, total=   7.5s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15, total=   5.6s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=15, total=   6.5s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15, total=   1.6s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15, total=   2.0s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15, total=   1.7s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15, total=   1.4s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=5, max_features=auto, max_depth=15, total=   1.5s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15, total=   2.2s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15, total=   2.9s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15, total=   2.4s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15, total=   2.2s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15 \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=15, total=   2.0s\n",
      "[CV] n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20, total=   3.7s\n",
      "[CV] n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20, total=   3.9s\n",
      "[CV] n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20, total=   3.9s\n",
      "[CV] n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20, total=   4.3s\n",
      "[CV] n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=5, min_samples_leaf=10, max_features=auto, max_depth=20, total=   3.8s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25, total=   8.1s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25, total=   5.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25, total=   5.7s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25, total=   5.7s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=25, total=   5.2s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, total=   4.8s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, total=   4.5s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, total=   5.7s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, total=   7.6s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, total=   6.5s\n",
      "[CV] n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15, total=   1.6s\n",
      "[CV] n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15, total=   1.5s\n",
      "[CV] n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15, total=   1.3s\n",
      "[CV] n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15, total=   2.1s\n",
      "[CV] n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15 \n",
      "[CV]  n_estimators=300, min_samples_split=15, min_samples_leaf=1, max_features=sqrt, max_depth=15, total=   1.6s\n",
      "[CV] n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   4.2s\n",
      "[CV] n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.8s\n",
      "[CV] n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   4.7s\n",
      "[CV] n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.6s\n",
      "[CV] n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=700, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.5s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20, total=   3.9s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20, total=   3.6s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20, total=   4.0s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20, total=   3.7s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=20, total=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 10, 15, 20, 25, 30], 'min_samples_split': [2, 5, 10, 15, 100], 'min_samples_leaf': [1, 2, 5, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.0608889920247728\n",
      "MSE: 2.939393492974054\n",
      "RMSE: 1.714465949785546\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# open a file, where you want to store the data\n",
    "file = open('student_rf.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(reg_rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = open('student_rf.pkl','rb')\n",
    "forest = pickle.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526636295439628"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
